## Book notes

Putting some half-fledged thoughts here as I read Mindstorms by Simon Papert. Feel free to make it a discussion rather than a monologue.

So far it's along the lines of Lockhart's Lament, strongly arguing a constructionist approach to a more humane and meaningful understanding of mathematics and other things we have to learn at school.

I definitely still believe that drilling and direct instruction are both necessary elements of mastering something, but as a general approach to education, i.e. at school, I think that there should be a much larger emphasis on connecting with interesting stuff, whether it is interesting because it is applicable and useful or because it is intrinsically beautiful/entertaining/etc. Extra practice should be something that students want to do because they desire to get a foot up in using what they're learning.

So how do we actually *learn* anything with this approach? Papert uses the idea that we apply mental models from cultural artifacts to learn new things. For instance, he was fascinated by automobiles as a young child and was able to apply many of those ideas to his learning such as gear ratios and Diophantine equations. I have a lot of questions like when connections with those models can actually be model, which models should be explicitly taught as opposed to experienced or constructed, how to prevent incorrect models, etc. that I hope are addressed in the rest of the book. 

An analogy used by Papert as with others (Suzuki) is that learning mathematics can be thought of like learning a first language, which children do pretty much automatically. Here's a quote I just read about learning language that ties in: "Connecting with native media is where the acquisition actually takes place. The SRS is just a tool to make it easier. In fact, SRS is to help make it a lazier process. You SRS words so that when you encounter a specific term for the second time, you don't have to fish for your dictionary."

I think we may have had a faulty approach with the analysis course because making it SRS-centric may be an unnecessary evil--experiencing the "culture" (basically Prof Su talking about balls and using periods) and autonomous model building should be primary and remembering facts secondary (slightly off the current topic but the notable absentee is "getting students to be better at applying those models and facts to solve hard problems"). 

How can we do better with the physics approach? We have the advantage that our audience is mostly people who already see math and physics as an end in itself and thus want the extra practice, so we could just argue (and even explicitly point out) that we are the (fun & optimized) drill portion of the educational experience. The main point with the SRS though is that I think my idea that you can SRS everything is at least partially flawed. SRS should be "Hey! I want/need to remember this single, describable, isolated fact." Then plop into SRS and a single invincible neuron is born. (Also, it may be that big abstract things could eventually become little facts when they are chunked and familiarized enough by someone. ALSO there may be some advantage to using SRS or something related to explore a new big idea that you can't quite get a grasp on and down into little bits at first. Hopefully sticking the phrase "random immersion" here will help me revisit this question at some later time.) One question we should address is whether it's advantageous to take over that decision process for the student. Another (which we've encountered endlessly) is how we optimally make that decision. Obviously we don't want to make students really good at a random x% of physic, but is it really necessary to drill every fact?

Anyway, the book's main thesis is that computers, when applied correctly, could be the means of revolutionizing education in the above manner. I share a feeling with him that there may be something fundamentally special about computers: the empowerment of programming, the ability to apply logical thinking as well as creative thinking, the greater spread of culture, and lots of powerful models provided by both computer science and software engineering. It's a little late to do anything too sophisticated with this for the summer (program a realistic physics engine for your virtual world so its citizens don't keep getting hurt in freak accidents!), but it's worth continuing to think about. I think something with a computer-sciencey mindset that provides a rich basis of cultural models and presents a goal of fluency and mastery while using computer tools when necessary (e.g. occasional drilling) would be a powerful formula for learning many things. The "AJATT method" as far as it exists in the collective minds of its followers (one of whom produced the above "native media" quote) is a good example of getting most of that for language learning, and I'll later give my thoughts on how the method in Mindstorms seems to do for programming/math/etc.

Comments on the second third. I'll just go for random notes instead of fancy schmancy paragraphs. Let me know if more cohesiveness is needed anywhere.

* Papert uses variations of Turtle, like in CS5, as the center of his educational methods. Each of the variations provides a "microworld" where students learn some ideas from a particular topic.
* He talks about Polya's heuristics and how these should be learned, which he aims to do through use of the Turtle model. Not sure how.
* A hypothetical dialogue about whether heavier objects fall faster. Reasoning proven wrong by considering tying two objects together. A good direction would be to do less of telling students they are wrong and more of convincing them of that through this kind of reasoning or experiment, i.e. by using the scientific method. 
* Some examples where challenging problems are supposedly aided by good geometric or physical intuition. But I'm not convinced that someone who has played with Turtle (his mantra is "play with turtle") more than I have would have came up with the same ideas he did. 
* It's interesting that Papert tries to bring together programming and intuition in contrast to Zeilberger who says that programming and computers reveal the limitations and futility of human intuition (http://www.math.rutgers.edu/~zeilberg/Opinion47.html). He addresses this basically by saying that they are separate modes of thinking that can each be used powerfully as a tool. 
* At what point are we going from constructing worlds where the intuition comes about naturally to a point where either the intuition is not developed for most people or has to be constructed in a convoluted manner to ensure it is learned? In other words, would direct instruction be better for some things?
* Good argument that New Math was flawed because the problem that students have with, say, arithmetic, isn't a lack of number sense but erring in the procedure. Students need to be more comfortable thinking about procedures and finding problems ("bugs") with them. 
* In explaining Piaget's work with math and in particular considering simultaneously the psychology and epistemology of learning, Papert seems to acknowledge that the microworlds are in fact very carefully constructed to support constructionism of that particular topic. So I think this has to be considered differently than any kind of free-form constructionism or even traditionally scaffolded constructionism (though I'm not familiar with those traditions).
* Really interesting possible explanation for Piaget conservationism development in a child

Last third

* For Papert, computational thinking seems almost utopian. He gives the example of the much later age at which child generally develop the ability to do combinatorial enumerations ("list of all pairs of colored beads"). He also argues that pure logic is not enough to cover thinking (be it human or AI). But is procedural thinking enough? How do Bayesian, quantum, evolutionary, or even just non-procedural programming play in? Or can we apply the Church-Turing thesis to arbitrarily extend the power of procedural thinking?
* Illustrated by the Brazilian "samba schools", he makes the case that good learning institutions must arise from cultural roots. He'd definitely be a fan of Project Euler, TopCoder, AoPS, even TeamLiquid, which I also think are powerful but still rudimentary learning centers.
* We need to bridge the gap between humanistic and technical fields, and the computer is a good medium for this. (Justification for my grad school plans, woohoo)
* "...in order to have a complete picture, we must [...] recognize the dialectical interaction between the content, the pedagogy, and the technology."
* More serious effort should be made towards making science learnable as the Turtle makes geometry and Newton's laws learnable.
* Pretty interesting stuff about Poincare's idea that conscious attempts won't solve difficult problems: the unconscious does the bulk of the work, and, through a mathematical sense of aesthetic, some ideas are brought serendipitously to the conscious.

## Related readings

* http://www.amazon.com/Childrens-Machine-Rethinking-School-Computer/dp/0465010636/
* http://www.amazon.com/Theories-Childhood-Introduction-Montessori-Vygotsky/dp/188483485X/
* http://www.amazon.com/Society-Mind-Marvin-Minsky/dp/0671657135/
* http://www.amazon.com/Zen-Art-Motorcycle-Maintenance-Inquiry/dp/0061673730/
* http://www.amazon.com/Cybernetics-Second-Control-Communication-Machine/dp/026273009X/
* http://www.amazon.com/Changing-Minds-Computers-Learning-Literacy/dp/0262541327/
* http://www.amazon.com/Bourbaki-Society-Mathematicians-Maurice-Mashaal/dp/0821839675/

## Open problems (GÃ¶del's Lost Letter style):

* What are some more good examples of "turtles"?
* Is building intuition through models worthwhile? When is it more or less effective?
* Where to start in revolutionizing school in some of the ways Papert suggests?

## Further discussion

 want to talk some more about this innocuous little bullet point and how it relates to us:
Really interesting possible explanation for Piaget conservationism development in a child
I may be introducing some new terms and ideas as I recall and expand on what Papert wrote (too lazy to reread).

Conservation: Pour liquid from wide glass A to tall glass B (without spilling). Is the amount of liquid the same in A and B? Of course, but it turns out that children don't learn this concept, called conservation, until a certain (fairly consistent) age. 
 
Papert's explanation: (Theory of competing agents) Consider agent A_height who says mindlessly "Tall things are more!". Nevermind how we know what taller or more are, but you can imagine that this develops early in a child. The presence of that agent alone prompts the child to say that the tall glass has more liquid. However, the child may eventually acquire A_width who says mindlessly "Wide things are more!" Now the child experiences some cognitive dissonance between A_h and A_w  (my introduction here) and then develops A_geom that says "Well, we actually need some care here." Finally, with this and some further interaction with the environment, the child develops the idea of conservation.

In Learnstream terms: The component breakdown helps us define these agents and, through lessons, plant them in the mind of the student. (Sinister.) SRS helps keep the agents stirred up in order to not die from brain rewiring and be ready to come to battle in some domain where there is either a lack of agency or another inaccurate agent that usually takes charge. 

Physics examples: Newton's third law. Why is there a common misconception about which force is bigger? A_{big shit} screams "BIG SCARY DESTROY CRUSH" at the slightest brush. How early do you think we develop that one? 

Nothing too insightful here, but we can reframe our goal as educators as creating agents that are more responsive in the appropriate situations. In other words, creating a trigger for A_{Newton's third law} whenever there are forces between two bodies.

Now think about something harder, like the monkey problem. Papert notes that students who received the problem tried to apply lever arms, conservation of energy, etc. Good agents to have. But how do we do tease out the _best_ agent for this particular situation? (Conservation of momentum, it turns out. I finally get his explanation.) From my experience, the best I can offer is to defer to the discussion about Poincare in Mindstorms: our unconscious processes diligently with a little bit of everything and when something "aesthetic" crops up with get a House moment and blurt out something that may or may not be sensical. And "aesthetic" may be nothing more than one agent making an explosion in the big battle. In other words, developing perfect agents is never achievable, so you sometimes have to brute force through some possibilities.

Remaining questions: How complex should these agents be? Is each tiny thing it's own agent, or do agents grow in both number and "personality", able to make finer distinctions? My (quite possibly flawed) heuristic for brain activity is "simple with many connections." So for the monkey problem, we have something like (lol ruby) { :pulley => :forces, :heights => :conservation_of_energy, :monkey => :banana, :velocity => :momentum, :no_external_force => :conservation_of_momentum } going on at 10000x scale in parallel in our (mostly unconscious) head. Along those lines, how does pattern matching work for triggers? Defined terms ("forces", "velocity") seem to work well as abstractions for triggers, as do certain settings ("A block on an incline plane...", "Two people on skis..."). Are there more subtle ones? (I imagine the abstracted triggers themselves are also triggered with a similar process.)

And another lesson from that last bit: diverge from stereotypical problems in order to broaden triggers. Just make conditions of applicability exact. E.g. if you explain Newton's 3rd law every time with trucks and flies, some students might come away with the impression, "Oh wow, flies are really fucking strong." 
